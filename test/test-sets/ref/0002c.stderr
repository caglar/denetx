using no cache
Reading from train-sets/0002.dat
num sources = 1
Num weight bits = 18
learning rate = 10
initial_t = 1
power_t = 0.5
predictions = 0002c.predict
only testing
average    since       example  example    current  current  current
loss       last        counter   weight      label  predict features
0.002471   0.002471          3      3.0     0.5498   0.5038      184
0.017674   0.032878          6      6.0     0.2681   0.5650      184
0.014220   0.010076         11     11.0     0.4315   0.5067      184
0.023766   0.033311         22     22.0     0.5519   0.5698      184
0.013887   0.004008         44     44.0     0.5514   0.5717      184
0.014306   0.014735         87     87.0     0.5140   0.5401      184
0.010668   0.007030        174    174.0     0.5596   0.5382      184
0.009100   0.007533        348    348.0     0.5475   0.4325      184
0.008705   0.008310        696    696.0     0.3421   0.6017      184
0.009201   0.009698       1392   1392.0     0.4996   0.5013      184
0.007251   0.005301       2784   2784.0     0.5090   0.5116      184
0.005945   0.004638       5568   5568.0     0.6413   0.4166      184
0.006057   0.006170      11135  11135.0     0.3869   0.5068      184
0.007267   0.008477      22269  22269.0     0.5063   0.4440      184
0.009011   0.010756      44537  44537.0     0.4905   0.4708      184

finished run
number of examples = 74746
weighted example sum = 6.952e+04
weighted label sum = 3.511e+04
average loss = 0.008502
best constant = 0.5051
best constant's loss = 0.25
total feature number = 13753264
