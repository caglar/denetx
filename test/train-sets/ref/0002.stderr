using no cache
Reading from train-sets/0002.dat
num sources = 1
final_regressor = models/0002.model
Num weight bits = 18
learning rate = 10
initial_t = 1
power_t = 0.5
learning_rate set to 10
average    since       example  example    current  current  current
loss       last        counter   weight      label  predict features
0.110447   0.110447          3      3.0     0.5498   0.3591       15
0.070578   0.030710          6      6.0     0.2681   0.0000       15
0.064146   0.056427         11     11.0     0.4315   0.0000       15
0.039467   0.014787         22     22.0     0.5519   0.5567       15
0.021355   0.003244         44     44.0     0.5514   0.5910       15
0.013396   0.005251         87     87.0     0.5140   0.5232       15
0.008875   0.004355        174    174.0     0.5596   0.5530       15
0.006074   0.003273        348    348.0     0.5475   0.5396       15
0.004134   0.002195        696    696.0     0.3421   0.4039       15
0.003038   0.001941       1392   1392.0     0.4996   0.4675       15
0.002267   0.001496       2784   2784.0     0.5090   0.5209       15
0.001955   0.001643       5568   5568.0     0.6413   0.5778       15
0.002054   0.002153      11135  11135.0     0.3869   0.4304       15
0.002184   0.002314      22269  22269.0     0.5063   0.5236       15
0.002400   0.002617      44537  44537.0     0.4905   0.4792       15

finished run
number of examples = 74746
weighted example sum = 6.952e+04
weighted label sum = 3.511e+04
average loss = 0.002451
best constant = 0.5051
best constant's loss = 0.25
total feature number = 1121190
